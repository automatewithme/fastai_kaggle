{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trail_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "U14YLd5k4Uts",
        "lnLg9M8v18Uw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "U14YLd5k4Uts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data downloading "
      ]
    },
    {
      "metadata": {
        "id": "waIyTaiM1LIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10418/123020/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1546326541&Signature=WfpXoHo9ZEdhCOlmzM9xAWqSXf4as%2BpzI6qIMMop8xRBfLV2eBan5p%2B92oQwvzYP%2F%2FqjE%2FOvU7w1SHFM6sinAD8rz5ElYkVyc8yN15f00ajjFWlTKDqFAtn4eyYZM8e9dKBrl3M2YBZlBwBc77cLX5rO%2B5NVPCzpXcne%2BT1PnztiYds5rGo0T46HNPvV3XYl6sM3nXlnupkw%2Fi%2BeucwAWnC%2B1LpvpWVvAXOY9DJchal6r4Z1QD5EEfkbUbFT0MIoaN2g5%2B3lqDYbet0zQtk0BK5II%2BHNodacslHpf77RQvPmpHEXg52uOi2K3XelgDtT39DmZBn4RByrJoy%2FnXrdIA%3D%3D\" -O \"sample_submission.csv\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7sjBm6D1PeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10418/123020/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1546326563&Signature=X15seZbJM9G1UsHs8FjI0IjgPjUuxaMOTX6FFPU672HTxxjxFaF98YDRxe0h4x6xRIIohG3VxGyz3TIIKMh2Q68xyXgedXK0qpmYajmZENR6opMH61GD5UtGcn%2FiaQq841xAgIhhANNbbeMHnMJGmV5TzNk%2BUgBbU%2B85kt5UQxD%2Bywv05ZdKLBBkhAiZFUWUD48rEaLgMWJW32Hvr7jTHD65a5%2FRABSIFbTKNAUjXwLwgqwBMFhOHCJWC%2FZkwIeYBS2Q4MpftGQ5IlvA%2BSQS9iuk9GWq7il67sVb8MPzRAihV%2BbZ7RLl814VLxMDDlmrqMdqsteVrjdOGsF0t17GEw%3D%3D\" -O \"train.csv\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UOHAsrn1QUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10418/123020/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1546326580&Signature=Xp4Ov64X%2BxooAFT8Lj2P9OdiAVneDHABZMUcJD5HXvy%2FR5%2F%2B9iGVCS08DDi04P%2F8wqScwDVreRpEE6xNvZzXcdxQ0AZ0xcpP6A8IAzKTEOLed%2BqCxf7YZXJJW75vMfRgqDvN7MjsrcGYXFGtBUaj6CtVcqdJ59AYbjKFaoJzjtW4rMHRRTwozTBdVoUq7Ru36fMcjb9MjMZZhkKdyNr9TaMo2Tiw1MEBxz4R3Wax%2B%2BxEZWFksXfdNCljX4c4RbV1y7yeIiUBIuZu1X8rsmZcVCyDxRrrgaxf%2BtCrPLLcSMFkHtaoLJeIrHj249cHqT5CeRx7fZAtnVlQZIE6bScuww%3D%3D\" -O \"test.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPL7iRDJ1RSU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10418/123020/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1546326595&Signature=AROAHUrXLjjgx2gyElYptPVyBh3sn8jPA%2FHcF2xureqQvF9AoWKT8QzM4Uqz2WvswqExQ1nJrYb747i2%2BT6DDQuvgMarjpfopKt%2FcUvHEbLpHbGRwPjiPW5M11h5ElC9wy%2BCC2YA25O2FOVN47iwq%2BgRHymkGla2T1kfUNBtQEcj57pjwQXzAYQ%2F91I6DpakdPVqPNW6FBUqTNWUyS%2Fug%2FXUOlA6h9fgMmNPR7QgS7RLcYXUCwGAZqqHSNbNfJyZqBQOiqagRcUhduIsta%2BQBEo4JLo8%2B4EF%2Bqlaxg87MLSFmM58HP5OunXI9LqVO7Vuq9ulvixzyueQDoL7BspJbg%3D%3D\" -O \"train.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WTfpIlAM1SRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/protein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R1hG1vgs1TTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -qq train.zip -d data/protein/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ejmb-FB91UAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -qq test.zip -d data/protein/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilf77x2J1Vdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv train.csv data/protein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8f-ERbH1V77",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnLg9M8v18Uw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Trails:"
      ]
    },
    {
      "metadata": {
        "id": "Fa4gqlyM1eIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from PIL import Image\n",
        "\n",
        "train_path = 'data/protein/train/'\n",
        "test_path = 'data/protein/test/'\n",
        "df = pd.read_csv('data/protein/train.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUgBEqwEHDwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a=df.iloc[4,0]\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtRJhZXnNiGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = 'data/protein/train'\n",
        "ids = a\n",
        "def open_rgby(path,id): #a function that reads RGBY image\n",
        "    colors = ['red','green','blue','yellow']\n",
        "    flags = cv2.IMREAD_GRAYSCALE\n",
        "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
        "           for color in colors]\n",
        "    return np.stack(img, axis=-1)\n",
        "x=open_rgby(path,ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uVT63jLOEAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_imgs(x):\n",
        "    columns = 4\n",
        "    bs = x.shape[0]\n",
        "    rows = min((bs+3)//4,4)\n",
        "    fig=plt.figure(figsize=(columns*4, rows*4))\n",
        "    for i in range(rows):\n",
        "        for j in range(columns):\n",
        "            idx = i+j*columns\n",
        "            fig.add_subplot(rows, columns, idx+1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow((x[idx,:,:,:3]*255).astype(np.int))\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "display_imgs(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tBB2YzMpG0LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def open_rgby(path,id): #a function that reads RGBY image\n",
        "    colors = ['red','green','blue','yellow']\n",
        "    flags = cv2.IMREAD_GRAYSCALE\n",
        "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
        "           for color in colors]\n",
        "    x= np.stack(img, axis=-1)\n",
        "  \n",
        "    columns = 4\n",
        "    bs = x.shape[0]\n",
        "    rows = min((bs+3)//4,4)\n",
        "    fig=plt.figure(figsize=(columns*4, rows*4))\n",
        "    for i in range(rows):\n",
        "        for j in range(columns):\n",
        "            idx = i+j*columns\n",
        "            fig.add_subplot(rows, columns, idx+1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow((x[idx,:,:,:3]*255).astype(np.int))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cqICEH0ETpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "dataFiles = os.listdir('data/protein/train/')\n",
        "\n",
        "for filename in dataFiles:\n",
        "\n",
        "    #strip off the file extension\n",
        "    name = os.path.splitext(filename)[0]\n",
        "\n",
        "    bw = Image.open('data/protein/train/%s' %(filename,))\n",
        "\n",
        "    #create the coloured overlays\n",
        "    red = Image.new('RGB',bw.size,(255,0,0))\n",
        "    green = Image.new('RGB',bw.size,(0,255,0))\n",
        "    blue = Image.new('RGB',bw.size,(0,0,255))\n",
        "    yellow = Image.new('RGB',bw.size,(255,255,0))\n",
        "\n",
        "    #create a mask using RGBA to define an alpha channel to make the overlay transparent\n",
        "    mask = Image.new('RGBA',bw.size,(0,0,0,123))\n",
        "\n",
        "    x=Image.composite(bw,red,mask).convert('RGB')\n",
        "    y=Image.composite(bw,green,mask).convert('RGB')\n",
        "    z=Image.composite(bw,blue,mask).convert('RGB')\n",
        "    a=Image.composite(bw,yellow,mask).convert('RGB')\n",
        "    \n",
        "    f, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(3,3), sharey=True)\n",
        "    title = ''\n",
        "\n",
        "    ax1.imshow(x)\n",
        "    ax1.set_title('Red')\n",
        "    ax2.imshow(y)\n",
        "    ax2.set_title('Green')\n",
        "    ax3.imshow(z)\n",
        "    ax3.set_title('Blue')\n",
        "    ax4.imshow(a)\n",
        "    ax4.set_title('Yellow')\n",
        "    f.suptitle(title, fontsize=20, y=0.62)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ckN6fqxu4aiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUibWtuz4n5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KMEnvcUL5Yet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image(basepath, image_id):\n",
        "    images = np.zeros(shape=(256,256,4))\n",
        "    r = Image.open(basepath+image_id+\"_red.png\").resize((256,256))\n",
        "    g = Image.open(basepath+image_id+\"_green.png\").resize((256,256))\n",
        "    b = Image.open(basepath+image_id+\"_blue.png\").resize((256,256))\n",
        "    y = Image.open(basepath+image_id+\"_yellow.png\").resize((256,256))\n",
        "\n",
        "    images[:,:,0] = np.asarray(r)\n",
        "    images[:,:,1] = np.asarray(g)\n",
        "    images[:,:,2] = np.asarray(b)\n",
        "    images[:,:,3] = np.asarray(y)\n",
        "    \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usytWk0CFTXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Show(sample):\n",
        "    f, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(3,3), sharey=True)\n",
        "\n",
        "    title = ''\n",
        "    \n",
        "    labels =sample['target']\n",
        "                \n",
        "    for i, label in enumerate(LABELS):\n",
        "        if labels[i] == 1:\n",
        "            if title == '':\n",
        "                title += label\n",
        "            else:\n",
        "                title += \" & \" + label\n",
        "            \n",
        "    ax1.imshow(sample['image'][0,:,:],cmap=\"hot\")\n",
        "    ax1.set_title('Red')\n",
        "    ax2.imshow(sample['image'][1,:,:],cmap=\"copper\")\n",
        "    ax2.set_title('Green')\n",
        "    ax3.imshow(sample['image'][2,:,:],cmap=\"bone\")\n",
        "    ax3.set_title('Blue')\n",
        "    ax4.imshow(sample['image'][3,:,:],cmap=\"afmhot\")\n",
        "    ax4.set_title('Yellow')\n",
        "    f.suptitle(title, fontsize=20, y=0.62)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lR75Dh9aFVke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "idxs = random.sample(range(1, dataset.df.shape[0]), 3)\n",
        "\n",
        "for idx in idxs:\n",
        "    Show(dataset[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRAiKa204pWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOvBk8oXUvKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Program"
      ]
    },
    {
      "metadata": {
        "id": "GNi-1KFmUutX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "DATASET_SIZE = 8000\n",
        "BATCH_SIZE = 200\n",
        "W = H = 256\n",
        "\n",
        "train_path = 'data/protein/train/'\n",
        "test_path = 'data/protein/test/'\n",
        "\n",
        "LABEL_MAP = {\n",
        "0: \"Nucleoplasm\" ,\n",
        "1: \"Nuclear membrane\"   ,\n",
        "2: \"Nucleoli\"   ,\n",
        "3: \"Nucleoli fibrillar center\",   \n",
        "4: \"Nuclear speckles\"   ,\n",
        "5: \"Nuclear bodies\"   ,\n",
        "6: \"Endoplasmic reticulum\"   ,\n",
        "7: \"Golgi apparatus\"  ,\n",
        "8: \"Peroxisomes\"   ,\n",
        "9:  \"Endosomes\"   ,\n",
        "10: \"Lysosomes\"   ,\n",
        "11: \"Intermediate filaments\"  , \n",
        "12: \"Actin filaments\"   ,\n",
        "13: \"Focal adhesion sites\"  ,\n",
        "14: \"Microtubules\"   ,\n",
        "15: \"Microtubule ends\"   ,\n",
        "16: \"Cytokinetic bridge\"   ,\n",
        "17: \"Mitotic spindle\"  ,\n",
        "18: \"Microtubule organizing center\",  \n",
        "19: \"Centrosome\",\n",
        "20: \"Lipid droplets\"   ,\n",
        "21: \"Plasma membrane\"  ,\n",
        "22: \"Cell junctions\"   ,\n",
        "23: \"Mitochondria\"   ,\n",
        "24: \"Aggresome\"   ,\n",
        "25: \"Cytosol\" ,\n",
        "26: \"Cytoplasmic bodies\",\n",
        "27: \"Rods & rings\"}\n",
        "\n",
        "LABELS = []\n",
        "\n",
        "for label in LABEL_MAP.values():\n",
        "    LABELS.append(label)\n",
        "    \n",
        "train_csv_path = 'data/protein/train.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JrxR-vZQ6Zli",
        "colab_type": "code",
        "outputId": "0dd96b4d-dbbb-424c-d221-dff1023afc91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "protein = pd.read_csv(train_csv_path)\n",
        "n=25\n",
        "img_name = protein.iloc[n,0]\n",
        "print('Image name: {}'.format(img_name))\n",
        "\n",
        "labels = protein.iloc[n,1:]\n",
        "labels = protein.iloc[n,1:]\n",
        "#print('Label shape: {}'.format(labels.shape))\n",
        "print('Labels: {}'.format(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image name: 004bf4c6-bbc6-11e8-b2bc-ac1f6b6435d0\n",
            "Labels: Target    16 6\n",
            "Name: 25, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LjJ0GK3UVGmM",
        "colab_type": "code",
        "outputId": "b8d6ed78-2c86-4fb7-dae0-e57a0df197c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(train_csv_path)\n",
        "\n",
        "TRAINING_SAMPLES = df.shape[0]\n",
        "\n",
        "print(\"we have \" + str(TRAINING_SAMPLES) + \" different samples\")\n",
        "print(\"And there are \"+  str(len(df.Target.unique())) + \" different combinations of labels in our dataset\")\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"dark\")\n",
        "\n",
        "n = 20\n",
        "\n",
        "values = df['Target'].value_counts()[:n].keys().tolist()\n",
        "counts = df['Target'].value_counts()[:n].tolist()\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "pal = sns.cubehelix_palette(n, start=2, rot=0, dark=0, light=.75, reverse=True)\n",
        "g = sns.barplot(y=counts, x=values, palette=pal)\n",
        "g.set_title(str(n)+\" MOST COMMON LABEL COMBINATIONS\")\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we have 31072 different samples\n",
            "And there are 582 different combinations of labels in our dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAGDCAYAAAAlPdtBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1711b11080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Bc781IlLVH2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def load_image(basepath, image_id):\n",
        "    images = np.zeros(shape=(256,256,4))\n",
        "    r = Image.open(basepath+image_id+\"_red.png\").resize((256,256))\n",
        "    g = Image.open(basepath+image_id+\"_green.png\").resize((256,256))\n",
        "    b = Image.open(basepath+image_id+\"_blue.png\").resize((256,256))\n",
        "    y = Image.open(basepath+image_id+\"_yellow.png\").resize((256,256))\n",
        "\n",
        "    images[:,:,0] = np.asarray(r)\n",
        "    images[:,:,1] = np.asarray(g)\n",
        "    images[:,:,2] = np.asarray(b)\n",
        "    images[:,:,3] = np.asarray(y)\n",
        "    \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbtNZyYKVIxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "targets = df['Target'].value_counts().keys()\n",
        "counts = df['Target'].value_counts().values\n",
        "\n",
        "how_many = counts/TRAINING_SAMPLES*DATASET_SIZE\n",
        "\n",
        "# at least one example of each possible combination of labels..\n",
        "how_many = how_many.astype('int')+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bwAv-OGjVKsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from skimage import io, transform\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "classes = np.arange(0,28)\n",
        "mlb = MultiLabelBinarizer(classes)\n",
        "mlb.fit(classes)\n",
        "\n",
        "class HumanProteinDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file,transform=None, test=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            test (Boolean): the csv no contains labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.complete_df = pd.read_csv(csv_file)\n",
        "        \n",
        "        if not test:\n",
        "            self.path = train_path\n",
        "            self.loadData()\n",
        "        else:\n",
        "            self.path = test_path\n",
        "            self.df = self.complete_df\n",
        "            \n",
        "        self.transform = transform\n",
        "        \n",
        "    def CreateDummyVariables(self):\n",
        "        self.complete_df['Targets'] = self.complete_df['Target'].map(lambda x: list(map(int, x.strip().split())))\n",
        "            \n",
        "    def loadData(self):\n",
        "        self.CreateDummyVariables()\n",
        "        self.df = pd.DataFrame(columns=['Id','Target'])\n",
        "        for i, target in enumerate(targets):\n",
        "            fdf = self.complete_df[self.complete_df['Target'] == target]\n",
        "            sample = fdf.sample(n=how_many[i], replace=False)\n",
        "            self.df = self.df.append(sample)\n",
        "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        image = load_image(self.path, self.df['Id'].iloc[idx])\n",
        "        \n",
        "        sample = {'image': image}\n",
        "\n",
        "        if not self.test:\n",
        "            target = np.array(self.complete_df['Targets'].iloc[idx])\n",
        "            target = mlb.transform([target])\n",
        "            sample['target'] = target\n",
        "        \n",
        "        else:\n",
        "            sample['Id'] = self.df['Id'].iloc[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def shape(self):\n",
        "        return self.df.shape\n",
        "      \n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, target = sample['image'], sample['target']\n",
        "        image = sample['image']/255.0\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        # as same for targets\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'target': torch.from_numpy(target)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "851hiLVXVMDk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = HumanProteinDataset(train_csv_path, transform=ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPMsGcECU5S2",
        "colab_type": "code",
        "outputId": "45db71b6-54d1-4bae-a16e-4b11e9329ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "cell_type": "code",
      "source": [
        "i=35\n",
        "sample = dataset[i]\n",
        "print(i, sample['image'], sample['target'])\n",
        "  #print('Image name: {}'.format(sample))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35 tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64) tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6I_S4QTE4aTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Show(sample):\n",
        "    f, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(25,25), sharey=True)\n",
        "\n",
        "    title = ''\n",
        "    \n",
        "    labels =sample['target']\n",
        "                \n",
        "    for i, label in enumerate(LABELS):\n",
        "        if labels[i] == 1:\n",
        "            if title == '':\n",
        "                title += label\n",
        "            else:\n",
        "                title += \" & \" + label\n",
        "            \n",
        "    ax1.imshow(sample['image'][0,:,:],cmap=\"hot\")\n",
        "    ax1.set_title('Red')\n",
        "    ax2.imshow(sample['image'][1,:,:],cmap=\"copper\")\n",
        "    ax2.set_title('Green')\n",
        "    ax3.imshow(sample['image'][2,:,:],cmap=\"bone\")\n",
        "    ax3.set_title('Blue')\n",
        "    ax4.imshow(sample['image'][3,:,:],cmap=\"afmhot\")\n",
        "    ax4.set_title('Yellow')\n",
        "    f.suptitle(title, fontsize=20, y=0.62)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzMnFtCX4bf0",
        "colab_type": "code",
        "outputId": "3a8f08aa-73a0-4f31-aacd-f14eba07c0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "idxs = random.sample(range(1, dataset.df.shape[0]), 3)\n",
        "\n",
        "for idx in idxs:\n",
        "    Show(dataset[idx])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ec99246d40a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-d9220fafaed8>\u001b[0m in \u001b[0;36mShow\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mtitle\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABZ0AAAVyCAYAAABqW1BkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWOAqZ7nDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f16a6b93e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8KRz22_ZXt79",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def prepare_loaders():\n",
        "    dataset.loadData()\n",
        "    num_train = len(dataset)\n",
        "    indices = list(range(num_train))\n",
        "    val_size = int(0.45 * num_train) \n",
        "\n",
        "    # Random, non-contiguous split\n",
        "    validation_idx = np.random.choice(indices, size=val_size, replace=False)\n",
        "    train_idx = list(set(indices) - set(validation_idx))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    validation_sampler = SubsetRandomSampler(validation_idx)\n",
        "\n",
        "    dataset_sizes = {}\n",
        "\n",
        "    dataset_sizes['train'] = len(train_idx)\n",
        "    dataset_sizes['val'] = len(validation_idx)\n",
        "    \n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE,num_workers=0, sampler=train_sampler)\n",
        "    validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=0,sampler=validation_sampler)\n",
        "\n",
        "    dataloaders = {}\n",
        "\n",
        "    dataloaders['train'] = train_loader\n",
        "    dataloaders['val'] = validation_loader\n",
        "    \n",
        "    return (dataloaders, dataset_sizes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybF97Ch8XvRA",
        "colab_type": "code",
        "outputId": "88098a05-6b19-4bf1-d910-a6ad1b938401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "dataloaders, dataset_sizes = prepare_loaders()\n",
        "\n",
        "dataset.df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Target</th>\n",
              "      <th>Targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2eda3904-bbaa-11e8-b2ba-ac1f6b6435d0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>076a3b42-bbb1-11e8-b2ba-ac1f6b6435d0</td>\n",
              "      <td>5</td>\n",
              "      <td>[5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d39ce426-bba7-11e8-b2ba-ac1f6b6435d0</td>\n",
              "      <td>13 21</td>\n",
              "      <td>[13, 21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7b747b1e-bbb7-11e8-b2ba-ac1f6b6435d0</td>\n",
              "      <td>16 0</td>\n",
              "      <td>[16, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9f8967ec-bbc8-11e8-b2bc-ac1f6b6435d0</td>\n",
              "      <td>25 21</td>\n",
              "      <td>[25, 21]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Id Target   Targets\n",
              "0  2eda3904-bbaa-11e8-b2ba-ac1f6b6435d0      0       [0]\n",
              "1  076a3b42-bbb1-11e8-b2ba-ac1f6b6435d0      5       [5]\n",
              "2  d39ce426-bba7-11e8-b2ba-ac1f6b6435d0  13 21  [13, 21]\n",
              "3  7b747b1e-bbb7-11e8-b2ba-ac1f6b6435d0   16 0   [16, 0]\n",
              "4  9f8967ec-bbc8-11e8-b2bc-ac1f6b6435d0  25 21  [25, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "_Fl8V14UUCZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5i8Qm3nLnryf",
        "colab_type": "code",
        "outputId": "01ef687d-1a5d-4c9b-89d9-d9e0eedebfba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset)):\n",
        "  sample = dataset[i]\n",
        "  print(i, sample['image'].shape, sample['target'].shape)\n",
        "  #print('Image name: {}'.format(sample))\n",
        "  if i == 3:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([4, 256, 256]) torch.Size([1, 28])\n",
            "1 torch.Size([4, 256, 256]) torch.Size([1, 28])\n",
            "2 torch.Size([4, 256, 256]) torch.Size([1, 28])\n",
            "3 torch.Size([4, 256, 256]) torch.Size([1, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CW4Qrd8BT4kx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "protein = pd.read_csv(train_csv_path)\n",
        "n=25\n",
        "img_name = protein.iloc[n,0]\n",
        "print('Image name: {}'.format(img_name))\n",
        "\n",
        "labels = protein.iloc[n,1:]\n",
        "labels = protein.iloc[n,1:]\n",
        "#print('Label shape: {}'.format(labels.shape))\n",
        "print('Labels: {}'.format(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2RIspmU5bLw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = HumanProteinDataset(train_csv_path, transform=transform.Compose([\n",
        "                                                                           ToTensor(),\n",
        "                                                                           Rescale(512),\n",
        "                                                                           RandomCrop(224),\n",
        "                                                                           ToPILImage(),\n",
        "                                                                           Normalize(),\n",
        "                                                                           RandomHorizontalFlip(),\n",
        "                                                                           RandomVerticalFlip(),\n",
        "                                                                          ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFiDeDNUcVbR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Compose(object):\n",
        "    \"\"\"Composes several transforms together.\n",
        "\n",
        "    Args:\n",
        "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
        "\n",
        "    Example:\n",
        "        >>> transforms.Compose([\n",
        "        >>>     transforms.CenterCrop(10),\n",
        "        >>>     transforms.ToTensor(),\n",
        "        >>> ])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img):\n",
        "        for t in self.transforms:\n",
        "            img = t(img)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + '('\n",
        "        for t in self.transforms:\n",
        "            format_string += '\\n'\n",
        "            format_string += '    {0}'.format(t)\n",
        "        format_string += '\\n)'\n",
        "        return format_string\n",
        "\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
        "\n",
        "    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
        "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
        "    \"\"\"\n",
        "    \n",
        "    def __call__(self, pic):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
        "        \"\"\"\n",
        "        \n",
        "        image = sample['image']/255.0\n",
        "        totensor = transforms.ToTensor()\n",
        "        ret = {'image': totensor(image)}\n",
        "       \n",
        "        if \"target\" in sample.keys():\n",
        "            target = sample['target'][0]\n",
        "            ret['target'] = target\n",
        "        else:\n",
        "            ret['Id'] = sample['Id']\n",
        "                  \n",
        "        return ret          \n",
        "      \n",
        "      \"\"\"\"\n",
        "        Returns:\n",
        "            Tensor: Converted image.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "class ToPILImage(object):\n",
        "    \"\"\"Convert a tensor or an ndarray to PIL Image.\n",
        "\n",
        "    Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape\n",
        "    H x W x C to a PIL Image while preserving the value range.\n",
        "\n",
        "    Args:\n",
        "        mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).\n",
        "            If ``mode`` is ``None`` (default) there are some assumptions made about the input data:\n",
        "            1. If the input has 3 channels, the ``mode`` is assumed to be ``RGB``.\n",
        "            2. If the input has 4 channels, the ``mode`` is assumed to be ``RGBA``.\n",
        "            3. If the input has 1 channel, the ``mode`` is determined by the data type (i,e,\n",
        "            ``int``, ``float``, ``short``).\n",
        "\n",
        "    .. _PIL.Image mode: http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#modes\n",
        "    \"\"\"\n",
        "    def __init__(self, mode=None):\n",
        "        self.mode = mode\n",
        "\n",
        "    def __call__(self, basepath, image_id):\n",
        "      \n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\n",
        "        \"\"\"\n",
        "            \n",
        "      images = np.zeros(shape=(256,256,4))\n",
        "      r = Image.open(basepath+image_id+\"_red.png\").resize((256,256))\n",
        "      g = Image.open(basepath+image_id+\"_green.png\").resize((256,256))\n",
        "      b = Image.open(basepath+image_id+\"_blue.png\").resize((256,256))\n",
        "      y = Image.open(basepath+image_id+\"_yellow.png\").resize((256,256))\n",
        "\n",
        "      images[:,:,0] = np.asarray(r)\n",
        "      images[:,:,1] = np.asarray(g)\n",
        "      images[:,:,2] = np.asarray(b)\n",
        "      images[:,:,3] = np.asarray(y)\n",
        "    \n",
        "     return images     \n",
        "    \n",
        "        \"\"\"\"\n",
        "        Returns:\n",
        "            PIL Image: Image converted to PIL Image.\n",
        "\n",
        "        \"\"\"\n",
        "        #return F.to_pil_image(pic, self.mode)\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
        "    Given mean: ``(M1,...,Mn)`` and std: ``(S1,..,Sn)`` for ``n`` channels, this transform\n",
        "    will normalize each channel of the input ``torch.*Tensor`` i.e.\n",
        "    ``input[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
        "\n",
        "    Args:\n",
        "        mean (sequence): Sequence of means for each channel.\n",
        "        std (sequence): Sequence of standard deviations for each channel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Normalized Tensor image.\n",
        "        \"\"\"\n",
        "        return F.normalize(tensor, self.mean, self.std)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "\n",
        "\n",
        "class Resize(object):\n",
        "    \"\"\"Resize the input PIL Image to the given size.\n",
        "\n",
        "    Args:\n",
        "        size (sequence or int): Desired output size. If size is a sequence like\n",
        "            (h, w), output size will be matched to this. If size is an int,\n",
        "            smaller edge of the image will be matched to this number.\n",
        "            i.e, if height > width, then image will be rescaled to\n",
        "            (size * height / width, size)\n",
        "        interpolation (int, optional): Desired interpolation. Default is\n",
        "            ``PIL.Image.BILINEAR``\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
        "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to be scaled.\n",
        "    \n",
        "        Returns:\n",
        "            PIL Image: Rescaled image.\n",
        "        \"\"\"\n",
        "        \n",
        "        image, label = img['image'],  img['labels']\n",
        "        return F.resize(image, self.size, self.interpolation)\n",
        "\n",
        "    def __repr__(self):\n",
        "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
        "        return self.__class__.__name__ + '(size={0}, interpolation={1})'.format(self.size, interpolate_str)\n",
        "\n",
        "      \n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        # h and w are swapped for landmarks because for images,\n",
        "        # x and y axes are axis 1 and 0 respectively\n",
        "        landmarks = landmarks * [new_w / w, new_h / h]\n",
        "\n",
        "        return {'image': img, 'landmarks': landmarks}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PV999RsVO2_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Show(sample):\n",
        "    f, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(3,3), sharey=True)\n",
        "\n",
        "    title = ''\n",
        "    \n",
        "    labels =sample['target']\n",
        "                \n",
        "    for i, label in enumerate(LABELS):\n",
        "        if labels[i] == 1:\n",
        "            if title == '':\n",
        "                title += label\n",
        "            else:\n",
        "                title += \" & \" + label\n",
        "            \n",
        "    ax1.imshow(sample['image'][0,:,:],cmap=\"hot\")\n",
        "    ax1.set_title('Red')\n",
        "    ax2.imshow(sample['image'][1,:,:],cmap=\"copper\")\n",
        "    ax2.set_title('Green')\n",
        "    ax3.imshow(sample['image'][2,:,:],cmap=\"bone\")\n",
        "    ax3.set_title('Blue')\n",
        "    ax4.imshow(sample['image'][3,:,:],cmap=\"afmhot\")\n",
        "    ax4.set_title('Yellow')\n",
        "    f.suptitle(title, fontsize=20, y=0.62)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81avJrCUVQDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "idxs = random.sample(range(1, dataset.df.shape[0]), 3)\n",
        "\n",
        "for idx in idxs:\n",
        "    Show(dataset[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPvVAVMnVRLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def prepare_loaders():\n",
        "    dataset.loadData()\n",
        "    num_train = len(dataset)\n",
        "    indices = list(range(num_train))\n",
        "    val_size = int(0.45 * num_train) \n",
        "\n",
        "    # Random, non-contiguous split\n",
        "    validation_idx = np.random.choice(indices, size=val_size, replace=False)\n",
        "    train_idx = list(set(indices) - set(validation_idx))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    validation_sampler = SubsetRandomSampler(validation_idx)\n",
        "\n",
        "    dataset_sizes = {}\n",
        "\n",
        "    dataset_sizes['train'] = len(train_idx)\n",
        "    dataset_sizes['val'] = len(validation_idx)\n",
        "    \n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE,num_workers=0, sampler=train_sampler)\n",
        "    validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=0,sampler=validation_sampler)\n",
        "\n",
        "    dataloaders = {}\n",
        "\n",
        "    dataloaders['train'] = train_loader\n",
        "    dataloaders['val'] = validation_loader\n",
        "    \n",
        "    return (dataloaders, dataset_sizes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4qV8xliVpZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloaders, dataset_sizes = prepare_loaders()\n",
        "\n",
        "dataset.df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KjsOyoiOVqHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(      #input: 4xWxH\n",
        "            nn.Conv2d(4,8,5,1,2),        # input_channels, output_channels, kernel_size, stride, padding   \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2), #output: 8xW/2xH/2\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(      #input: 4xWxH\n",
        "            nn.Conv2d(8,16,5,1,2),        # input_channels, output_channels, kernel_size, stride, padding   \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2), #output: 16xW/4xH/4\n",
        "        )\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.out1 = nn.Linear( int(16 * W/4 * H/4), 900)   # fully connected layer, output 28 classes\n",
        "        self.out2 = nn.Linear( 900, 28)   # fully connected layer, output 28 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        output = self.drop_out(x)\n",
        "        output = self.out1(x)\n",
        "        output = self.out2(output)\n",
        "        return output, x    # return x for visualization\n",
        "\n",
        "def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform(m.weight)\n",
        "            m.bias.data.fill_(0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JOeAh_3BVsag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloaders, dataset_sizes = prepare_loaders()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubMWb-DjVsUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = {}\n",
        "accuracys = {}\n",
        "\n",
        "losses['train'] = []\n",
        "losses['val'] = []\n",
        "accuracys['train'] = []\n",
        "accuracys['val'] = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9ZBms8LV3tA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Train(model, epochs=10, criterion=nn.BCEWithLogitsLoss(reduction='sum'), optimizer= None):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.04, betas=(0.9, 0.99))\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"training with device: \" + str(device))\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        print('Epoch {}/{}'.format(epoch+1, epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "            running_loss = 0.0    \n",
        "            running_corrects = 0.0\n",
        "    \n",
        "            for i, data in enumerate(dataloaders[phase], 0):            \n",
        "                # get the inputs\n",
        "                inputs, labels = data['image'], data['target']\n",
        "\n",
        "                inputs, labels = inputs.to(device,dtype=torch.float), labels.to(device,dtype=torch.float)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)[0]\n",
        "                    preds = outputs > 0\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                 # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                labels = labels.data.byte()\n",
        "                running_corrects += torch.sum((labels == preds).all(1))\n",
        "                                \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            losses[phase].append(epoch_loss)\n",
        "            accuracys[phase].append(epoch_acc)\n",
        "            \n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                \n",
        "                \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_model(model,batch):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = batch\n",
        "    inputs = inputs.to(device,dtype=torch.float)\n",
        "    out = model(inputs)\n",
        "    out = out[0].cpu()\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnibyAyRV5-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model creation and initialization\n",
        "cnn = CNN()\n",
        "cnn.apply(init_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWZXPLGZV65B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "torch.cuda.empty_cache()\n",
        "cnn = Train(cnn, epochs=10,  criterion=nn.BCEWithLogitsLoss(reduction='sum'), optimizer = optim.Adam(cnn.parameters(), lr=0.001, betas=(0.9, 0.99)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}